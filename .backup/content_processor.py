"""
Content ProcessorModifies original content and generates promotional texts
ÙŠØ¹Ø¯Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£ØµÙ„ÙŠ ÙˆÙŠÙˆÙ„Ø¯ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªØ±ÙˆÙŠØ¬ÙŠØ©
"""

import openai
import random
from typing import Dict, List, Optional
from config import settings
from utils.logger import logger, log_api_call
from src.database import Database


class ContentProcessor:
 """
 Processes and modifies post content with AI
 ÙŠØ¹Ø§Ù„Ø¬ ÙˆÙŠØ¹Ø¯Ù„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
 """

 def __init__(self, database: Database):
 """
 Initialize content processor
 ØªÙ‡ÙŠØ¦Ø© Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰

 Args:
 database: Database instance"""
 self.database = database
 openai.api_key = settings.OPENAI_API_KEY
 self.model = settings.OPENAI_MODEL

 def _create_modification_prompt(self, original_text: str, modification_level: int = 40) -> str:
 """
 Create prompt for text modification
 Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Øµ

 Args:
 original_text: Original post textmodification_level: Modification percentageReturns:
 GPT promptGPT
 """
 return f"""Ø£Ù†Øª ÙƒØ§ØªØ¨ Ù…Ø­ØªÙˆÙ‰ Ù…Ø­ØªØ±Ù. Ù‚Ù… Ø¨Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ù†Ø³Ø¨Ø© ØªØ¹Ø¯ÙŠÙ„ {modification_level}%.

Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:
{original_text}

Ù…ØªØ·Ù„Ø¨Ø§Øª Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØµÙŠØ§ØºØ©:
1. Ø§Ø­ØªÙØ¸ Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© (Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬ØŒ Ø§Ù„Ø³Ø¹Ø±ØŒ Ø§Ù„ØªØ®ÙÙŠØ¶)
2. ØºÙŠÙ‘Ø± Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø¥Ù„Ù‰ Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ù…Ø®ØªÙ„ÙØ© ÙˆÙ…Ù†Ø§Ø³Ø¨Ø©
3. Ø£Ø¹Ø¯ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¬Ù…Ù„
4. Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø±Ø§Ø¯ÙØ§Øª ÙˆÙ…ØµØ·Ù„Ø­Ø§Øª Ù…Ø®ØªÙ„ÙØ©
5. ØºÙŠÙ‘Ø± Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ÙƒØªØ§Ø¨Ø© Ù‚Ù„ÙŠÙ„Ø§Ù‹ (Ù…Ù† Ø±Ø³Ù…ÙŠ Ù„ÙˆØ¯ÙˆØ¯ Ø£Ùˆ Ø§Ù„Ø¹ÙƒØ³)
6. Ø§Ø­Ø°Ù Ø£ÙŠ Ø£Ø±Ù‚Ø§Ù… Ù‡ÙˆØ§ØªÙ Ø£Ùˆ Ø¹Ù†Ø§ÙˆÙŠÙ† Ù…Ø­Ø¯Ø¯Ø©

Ù…Ù„Ø§Ø­Ø¸Ø©: Ù„Ø§ ØªØ¶Ù Ø±ÙˆØ§Ø¨Ø· Ø£Ùˆ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©. ÙÙ‚Ø· Ø£Ø¹Ø¯ ØµÙŠØ§ØºØ© Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯.

Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ø¯Ù„:"""

 def _create_promotional_prompt(self, product_name: str, category: str, trendyol_link: str) -> str:
 """
 Create prompt for Trendyol promotional text
 Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ Ù„Ù„Ù†Øµ Ø§Ù„ØªØ±ÙˆÙŠØ¬ÙŠ Ù„ØªØ±ÙŠÙ†Ø¯ÙˆÙ„

 Args:
 product_name: Product namecategory: Product categorytrendyol_link: Trendyol affiliate linkReturns:
 GPT promptGPT
 """
 templates = [
 "Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø³Ø¹Ø§Ø± ØªØ±ÙŠÙ†Ø¯ÙˆÙ„",
 "Ø¹Ø±ÙˆØ¶ ØªØ±ÙŠÙ†Ø¯ÙˆÙ„ Ø§Ù„Ø­ØµØ±ÙŠØ©",
 "ØªÙˆØµÙŠÙ„ Ù…Ø¬Ø§Ù†ÙŠ Ù…Ù† ØªØ±ÙŠÙ†Ø¯ÙˆÙ„",
 "ØªØ³ÙˆÙ‚ Ø£ÙˆÙ†Ù„Ø§ÙŠÙ† Ù…Ù† ØªØ±ÙŠÙ†Ø¯ÙˆÙ„"
 ]

 template_choice = random.choice(templates)

 return f"""Ø§ÙƒØªØ¨ Ù†Øµ ØªØ±ÙˆÙŠØ¬ÙŠ Ù‚ØµÙŠØ± (2-3 Ø£Ø³Ø·Ø± ÙÙ‚Ø·) Ù„ØªØ´Ø¬ÙŠØ¹ Ø§Ù„Ù†Ø§Ø³ Ø¹Ù„Ù‰ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ÙÙŠ ØªØ±ÙŠÙ†Ø¯ÙˆÙ„.

Ø§Ù„Ù…Ù†ØªØ¬: {product_name}
Ø§Ù„ÙØ¦Ø©: {category}
Ø§Ù„Ø±Ø§Ø¨Ø·: {trendyol_link}
Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: {template_choice}

Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª:
1. Ù†Øµ Ù‚ØµÙŠØ± ÙˆØ¬Ø°Ø§Ø¨
2. ÙŠØ´Ø¬Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© (Ù„ÙŠØ³ Ø¥Ù„Ø²Ø§Ù… Ø´Ø±Ø§Ø¡)
3. ÙŠØ°ÙƒØ± Ù…ÙŠØ²Ø© (Ù…Ø«Ù„: ØªÙˆØµÙŠÙ„ Ù…Ø¬Ø§Ù†ÙŠØŒ Ø£Ø³Ø¹Ø§Ø± Ù…Ù†Ø§ÙØ³Ø©ØŒ ØªØ´ÙƒÙŠÙ„Ø© ÙˆØ§Ø³Ø¹Ø©)
4. ÙŠØ­ØªÙˆÙŠ Ø¥ÙŠÙ…ÙˆØ¬ÙŠ ÙˆØ§Ø­Ø¯ Ø£Ùˆ Ø§Ø«Ù†ÙŠÙ† Ù…Ù†Ø§Ø³Ø¨ÙŠÙ†
5. Ù„Ø§ ØªØ°ÙƒØ± Ø£Ø³Ø¹Ø§Ø± Ù…Ø­Ø¯Ø¯Ø©

Ø§Ù„Ù†Øµ Ø§Ù„ØªØ±ÙˆÙŠØ¬ÙŠ:"""

 def _generate_hashtags(self, source: str, category: str, product_name: str) -> str:
 """
 Generate smart hashtags
 ØªÙˆÙ„ÙŠØ¯ Ù‡Ø§Ø´ØªØ§Ù‚Ø§Øª Ø°ÙƒÙŠØ©

 Args:
 source: Source store namecategory: Product categoryproduct_name: Product nameReturns:
 Hashtags string"""
 hashtags = []

 # Source store hashtagssource_tags = {
 "Al Othaim": ["#Ø§Ù„Ø¹Ø«ÙŠÙ…", "#Ø¹Ø±ÙˆØ¶_Ø§Ù„Ø¹Ø«ÙŠÙ…"],
 "Al Saif": ["#Ø§Ù„Ø³ÙŠÙ_ØºØ§Ù„ÙŠØ±ÙŠ", "#Ø§Ù„Ø³ÙŠÙ"],
 "Safaco": ["#ØµØ§ÙÙƒÙˆ", "#Safaco"],
 "Panda": ["#Ø¨Ù†Ø¯Ù‡", "#Panda"]
 }

 if source in source_tags:
 hashtags.extend(source_tags[source])

 # Trendyol hashtagshashtags.extend(["#ØªØ±ÙŠÙ†Ø¯ÙˆÙ„", "#Trendyol"])

 # Category hashtagscategory_tags = {
 "Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§Øª": ["#Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§Øª", "#ØªÙ‚Ù†ÙŠØ©"],
 "Ù…Ù„Ø§Ø¨Ø³": ["#Ù…Ù„Ø§Ø¨Ø³", "#Ø£Ø²ÙŠØ§Ø¡"],
 "Ù…Ù†Ø²Ù„": ["#Ù…Ù†Ø²Ù„", "#Ø¯ÙŠÙƒÙˆØ±"],
 "Ø·Ø¹Ø§Ù…": ["#Ø·Ø¹Ø§Ù…", "#Ù…Ø£ÙƒÙˆÙ„Ø§Øª"],
 "Ø£Ø¬Ù‡Ø²Ø©": ["#Ø£Ø¬Ù‡Ø²Ø©", "#Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§Øª"]
 }

 for key, tags in category_tags.items():
 if key in category:
 hashtags.extend(tags[:1]) # Add one category tag
 break

 # General hashtagsgeneral = ["#Ø¹Ø±ÙˆØ¶", "#ØªØ®ÙÙŠØ¶Ø§Øª", "#Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©", "#ØªÙˆÙÙŠØ±", "#ØªØ³ÙˆÙ‚_Ø§ÙˆÙ†Ù„Ø§ÙŠÙ†"]
 hashtags.extend(random.sample(general, 2))

 # Limit to configured rangecount = random.randint(settings.MIN_HASHTAGS, settings.MAX_HASHTAGS)
 selected = hashtags[:count]

 return " ".join(selected)

 async def process_post(
 self,
 post_id: str,
 original_text: str,
 source_page: str,
 source_website: str,
 analysis: Dict,
 trendyol_match: Dict
 ) -> Optional[Dict]:
 """
 Process a complete post with modifications and promotional content
 Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù†Ø´ÙˆØ± ÙƒØ§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ±ÙˆÙŠØ¬ÙŠ

 Args:
 post_id: Post IDoriginal_text: Original post textsource_page: Source page namesource_website: Source website URLanalysis: Post analysis resultstrendyol_match: Trendyol match dataReturns:
 Processed post data"""
 logger.info(f"âš™ï¸ Processing post: {post_id}")

 try:
 # ================================================================
 # STEP 1: Modify original text# ================================================================

 modification_level = random.randint(
 settings.MIN_MODIFICATION_PERCENT,
 settings.MAX_MODIFICATION_PERCENT
 )

 modification_prompt = self._create_modification_prompt(original_text, modification_level)

 modification_response = openai.ChatCompletion.create(
 model=self.model,
 messages=[
 {"role": "system", "content": "Ø£Ù†Øª ÙƒØ§ØªØ¨ Ù…Ø­ØªÙˆÙ‰ Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØµÙŠØ§ØºØ©."},
 {"role": "user", "content": modification_prompt}
 ],
 temperature=0.7,
 max_tokens=300
 )

 modified_text = modification_response.choices[0].message.content.strip()
 log_api_call("OpenAI", "text_modification", 200)

 # ================================================================
 # STEP 2: Generate promotional text# ================================================================

 promotional_prompt = self._create_promotional_prompt(
 analysis.get('product_name', ''),
 analysis.get('category', ''),
 trendyol_match.get('trendyol_link', '')
 )

 promo_response = openai.ChatCompletion.create(
 model=self.model,
 messages=[
 {"role": "system", "content": "Ø£Ù†Øª ÙƒØ§ØªØ¨ Ù…Ø­ØªÙˆÙ‰ ØªØ³ÙˆÙŠÙ‚ÙŠ Ù…Ø­ØªØ±Ù."},
 {"role": "user", "content": promotional_prompt}
 ],
 temperature=0.8,
 max_tokens=150
 )

 promotional_text = promo_response.choices[0].message.content.strip()
 log_api_call("OpenAI", "promotional_generation", 200)

 # ================================================================
 # STEP 3: Generate hashtags# ================================================================

 hashtags = self._generate_hashtags(
 source_page,
 analysis.get('category', ''),
 analysis.get('product_name', '')
 )

 # ================================================================
 # STEP 4: Create source attribution# ================================================================

 source_attribution = f"ğŸ“ Ø§Ù„Ù…ØµØ¯Ø±: {source_page}"
 if source_website:
 source_attribution += f"{source_website}"

 # ================================================================
 # STEP 5: Combine all parts# ================================================================

 final_content = f"""{modified_text}

---
{promotional_text}
ğŸ”— {trendyol_match.get('trendyol_link', '')}

{source_attribution}

{hashtags}"""

 # ================================================================
 # STEP 6: Save to database# ================================================================

 await self.database.connection.execute("""
 INSERT OR REPLACE INTO processed_posts
 (post_id, modified_text, promotional_text, hashtags, source_attribution, final_content)
 VALUES (?, ?, ?, ?, ?, ?)
 """, (
 post_id,
 modified_text,
 promotional_text,
 hashtags,
 source_attribution,
 final_content
 ))
 await self.database.connection.commit()

 logger.info(f"âœ… Processed successfully: {post_id}")

 return {
 'post_id': post_id,
 'modified_text': modified_text,
 'promotional_text': promotional_text,
 'hashtags': hashtags,
 'source_attribution': source_attribution,
 'final_content': final_content,
 'trendyol_link': trendyol_match.get('trendyol_link', '')
 }

 except Exception as e:
 logger.error(f"âŒ Processing failed: {e}")
 await self.database.log_warning(
 "processing_error",
 f"Failed to process post {post_id}: {str(e)}",
 "ContentProcessor"
 )
 return None


# ============================================================================
# STANDALONE PROCESSING FUNCTION# ============================================================================

async def run_processing_cycle(database: Database) -> int:
 """
 Process posts that have been analyzed and matched
 Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªØ­Ù„ÙŠÙ„Ù‡Ø§ ÙˆÙ…Ø·Ø§Ø¨Ù‚ØªÙ‡Ø§

 Args:
 database: Database instanceReturns:
 Number of posts processed"""
 processor = ContentProcessor(database)

 # Get posts ready for processingasync with database.connection.execute("""
 SELECT
 cp.post_id, cp.original_text, cp.source_page, cp.source_website,
 ap.product_name, ap.category, ap.keywords,
 tm.trendyol_link, tm.confidence_score
 FROM collected_posts cp
 JOIN analyzed_posts ap ON cp.post_id = ap.post_id
 JOIN trendyol_matches tm ON cp.post_id = tm.post_id
 LEFT JOIN processed_posts pp ON cp.post_id = pp.post_id
 WHERE pp.post_id IS NULL AND ap.is_suitable = 1
 LIMIT 20
 """) as cursor:
 rows = await cursor.fetchall()
 posts = [dict(row) for row in rows]

 if not posts:
 logger.info("â„¹ï¸ No posts to process")
 return 0

 logger.info(f"âš™ï¸ Processing {len(posts)} posts{len(posts)} Ù…Ù†Ø´ÙˆØ±")

 processed_count = 0

 for post in posts:
 analysis = {
 'product_name': post['product_name'],
 'category': post['category'],
 'keywords': post['keywords']
 }

 trendyol_match = {
 'trendyol_link': post['trendyol_link'],
 'confidence_score': post['confidence_score']
 }

 result = await processor.process_post(
 post['post_id'],
 post['original_text'],
 post['source_page'],
 post['source_website'],
 analysis,
 trendyol_match
 )

 if result:
 processed_count += 1

 logger.info(f"âœ… Processing complete: {processed_count}/{len(posts)}")
 return processed_count

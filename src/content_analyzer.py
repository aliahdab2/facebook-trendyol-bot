"""
Content AnalyzerAnalyzes posts using GPT-3.5 to extract product information
ÙŠØ­Ù„Ù„ Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-3.5 Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù†ØªØ¬
"""

import openai
import json
from typing import Dict, Optional
from config import settings
from utils.logger import logger, log_api_call, log_post_activity
from src.database import Database


class ContentAnalyzer:
 """
 Analyzes post content using AI
 ÙŠØ­Ù„Ù„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
 """

 def __init__(self, database: Database):
 """
 Initialize content analyzer
 ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰

 Args:
 database: Database instance"""
 self.database = database
 openai.api_key = settings.OPENAI_API_KEY
 self.model = settings.OPENAI_MODEL

 def _create_analysis_prompt(self, text: str, source: str) -> str:
 """
 Create analysis prompt for GPT
 Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ ØªØ­Ù„ÙŠÙ„ Ù„Ù€ GPT

 Args:
 text: Post textsource: Source page nameReturns:
 Formatted prompt"""
 return f"""Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø­ØªÙˆÙ‰ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù„Ù„Ù…ØªØ§Ø¬Ø± Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©.

Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† Ù…ØªØ¬Ø± {source} ÙˆØ§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨ØµÙŠØºØ© JSON:

Ø§Ù„Ù†Øµ:
{text}

ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ JSON ÙÙ‚Ø· Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„:
{{
 "product_name": "Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
 "category": "Ø§Ù„ÙØ¦Ø© (Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§ØªØŒ Ù…Ù„Ø§Ø¨Ø³ØŒ Ù…Ù†Ø²Ù„ØŒ Ø·Ø¹Ø§Ù…ØŒ Ø¥Ù„Ø®)",
 "keywords": ["ÙƒÙ„Ù…Ø©1", "ÙƒÙ„Ù…Ø©2", "ÙƒÙ„Ù…Ø©3"],
 "price": "Ø§Ù„Ø³Ø¹Ø± Ø¥Ù† ÙˆØ¬Ø¯",
 "discount": "Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ®ÙÙŠØ¶ Ø¥Ù† ÙˆØ¬Ø¯Øª",
 "is_suitable": true/false,
 "quality_score": 0.0-1.0,
 "reason": "Ø³Ø¨Ø¨ Ù‚ØµÙŠØ± Ù„Ù„ØªÙ‚ÙŠÙŠÙ…"
}}

Ù…Ù„Ø§Ø­Ø¸Ø§Øª:
- is_suitable = true Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù†Ø´ÙˆØ± ÙŠØ¹Ø±Ø¶ Ù…Ù†ØªØ¬ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†Ø´Ø±
- is_suitable = false Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù†Ø´ÙˆØ± ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨ (ØªÙ‡Ù†Ø¦Ø©ØŒ Ø¥Ø¹Ù„Ø§Ù† ÙˆØ¸ÙŠÙØ©ØŒ Ø¥Ù„Ø®)
- quality_score = ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ù…Ù† 0 Ø¥Ù„Ù‰ 1
- keywords = ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù‡Ù…Ø© Ù„Ù„Ø¨Ø­Ø« ÙˆØ§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©"""

 async def analyze_post(self, post_id: str, text: str, source: str) -> Optional[Dict]:
 """
 Analyze a single post
 ØªØ­Ù„ÙŠÙ„ Ù…Ù†Ø´ÙˆØ± ÙˆØ§Ø­Ø¯

 Args:
 post_id: Post IDtext: Post textsource: Source pageReturns:
 Analysis results"""
 if not text or len(text.strip()) < 10:
 logger.warning(f"âš ï¸ Post too short to analyze: {post_id}")
 return None

 log_post_activity("Analyzing", post_id, source)

 try:
 prompt = self._create_analysis_prompt(text, source)

 response = openai.ChatCompletion.create(
 model=self.model,
 messages=[
 {"role": "system", "content": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø­ØªÙˆÙ‰ Ø®Ø¨ÙŠØ±. Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·."},
 {"role": "user", "content": prompt}
 ],
 temperature=0.3,
 max_tokens=500
 )

 log_api_call("OpenAI", "chat/completions", 200)

 # Parse responsecontent = response.choices[0].message.content.strip()

 # Extract JSON from responseJSON Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
 if "```json" in content:
 content = content.split("```json")[1].split("```")[0].strip()
 elif "```" in content:
 content = content.split("```")[1].split("```")[0].strip()

 analysis = json.loads(content)

 # Save analysis to databaseawait self.database.save_analysis(post_id, analysis)

 # Log resultsuitable = "âœ… Suitable" if analysis.get('is_suitable') else "âŒ Not suitable"
 logger.info(f"{suitable} - {analysis.get('product_name', 'Unknown')} - Score: {analysis.get('quality_score', 0):.2f}")

 return analysis

 except json.JSONDecodeError as e:
 logger.error(f"âŒ Failed to parse JSONJSON: {e}")
 logger.error(f"Response content: {content}")
 return None

 except Exception as e:
 logger.error(f"âŒ Analysis failed: {e}")
 await self.database.log_warning(
 "analysis_error",
 f"Failed to analyze post {post_id}: {str(e)}",
 "ContentAnalyzer"
 )
 return None

 async def analyze_batch(self, posts: list) -> list:
 """
 Analyze multiple posts
 ØªØ­Ù„ÙŠÙ„ Ø¹Ø¯Ø© Ù…Ù†Ø´ÙˆØ±Ø§Øª

 Args:
 posts: List of posts to analyzeReturns:
 List of analysis results"""
 logger.info(f"ğŸ” Analyzing {len(posts)} posts{len(posts)} Ù…Ù†Ø´ÙˆØ±")

 results = []

 for post in posts:
 analysis = await self.analyze_post(
 post['post_id'],
 post.get('text', ''),
 post['source_page']
 )

 if analysis:
 results.append({
 'post_id': post['post_id'],
 'analysis': analysis
 })

 # Filter suitable postssuitable = [r for r in results if r['analysis'].get('is_suitable', False)]

 logger.info(f"âœ… Analysis complete: {len(suitable)}/{len(results)} suitable")

 return results

 async def select_best_posts(self, analyzed_posts: list, max_count: int = None) -> list:
 """
 Select best posts based on quality score
 Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¬ÙˆØ¯Ø©

 Args:
 analyzed_posts: List of analyzed postsmax_count: Maximum posts to selectReturns:
 Selected best posts"""
 if max_count is None:
 max_count = settings.MAX_POSTS_PER_DAY

 # Filter suitable postssuitable = [p for p in analyzed_posts if p['analysis'].get('is_suitable', False)]

 # Sort by quality scoresorted_posts = sorted(
 suitable,
 key=lambda x: x['analysis'].get('quality_score', 0),
 reverse=True
 )

 # Select top postsselected = sorted_posts[:max_count]

 logger.info(f"ğŸ¯ Selected {len(selected)} best posts{len(selected)} Ù…Ù†Ø´ÙˆØ±")

 return selected


# ============================================================================
# STANDALONE ANALYSIS FUNCTION# ============================================================================

async def run_analysis_cycle(database: Database) -> int:
 """
 Run analysis on unprocessed posts
 ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©

 Args:
 database: Database instanceReturns:
 Number of posts analyzed"""
 analyzer = ContentAnalyzer(database)

 # Get unprocessed postsposts = await database.get_unprocessed_posts(limit=50)

 if not posts:
 logger.info("â„¹ï¸ No posts to analyze")
 return 0

 # Analyze postsresults = await analyzer.analyze_batch(posts)

 # Mark as processedfor post in posts:
 await database.mark_post_as_processed(post['post_id'])

 return len(results)
